<!DOCTYPE html>
<html lang ="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta http-equiv="X-UA-Compatible" content="ie-edge" />

    <title>Document</title>

    <style>
        body { background-image: url(./Covidpic2.jpeg);}
    </style>

</head>
<body>



    <audio src="./54639794.mp3" id="audio"></audio>
    </br></br></br>
    <center><video height="500" width="500" id="video"></video></center>
    <canvas id="canvas"></canvas>
    <script src="https://cdn.jsdelivr.net/npm/handtrackjs/dist/handtrack.min.js"></script>
    <script>
        // JavaScript source code

        //navigator.mediaDevices.getUserMedia({video: {}}) .then((stream)=> {video.srcObject = stream;}, (err)=> console.error(err));
        //alert("hello");


        const modelParams = {
            flipHorizontal: true,   // flip e.g for video
            imageScaleFactor: .79,  // reduce input image size for gains in speed.
            maxNumBoxes: 20,        // maximum number of boxes to detect
            iouThreshold: 0.3,      // ioU threshold for non-max suppression
            scoreThreshold: .79,    // confidence threshold for predictions.
        }
        navigator.getUserMedia = navigator.getUserMedia ||
            navigator.webkitGetUserMedia ||
            navigator.mozGetUserMedia ||
            navigator.msGetUserMedia;


        const video = document.querySelector('#video');
        const audio = document.querySelector('#audio');
        const canvas = document.querySelector('#canvas');
        const context = canvas.getContext('2d');
        let model;




        handTrack.startVideo(video).then(status => {
            if (status) {
                navigator.getUserMedia(
                    { video: {} },
                    stream => {

                        video.srcObject = stream;
                        setInterval(runDetection, 500);


                    },
                    err => console.log(err)
                );
            }
        });

        function runDetection() {
            model.detect(video).then(predictions => {
                console.log(predictions);
                if (predictions.length > 0) {
                    //alert("get ur hands off yo face");
                    audio.play();
                }

            });
        }


        handTrack.load(modelParams).then(lmodel => {
            model = lmodel;
        });


    </script>
</body>
</html>